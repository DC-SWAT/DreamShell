diff -ruN gcc-9.3.0/gcc/configure gcc-9.3.0-kos/gcc/configure
--- gcc-9.3.0/gcc/configure	2020-03-12 07:08:30.000000000 -0400
+++ gcc-9.3.0-kos/gcc/configure	2020-04-03 16:07:04.540000000 -0400
@@ -11862,7 +11862,7 @@
     target_thread_file='single'
     ;;
   aix | dce | lynx | mipssde | posix | rtems | \
-  single | tpf | vxworks | win32)
+  single | tpf | vxworks | win32 | kos)
     target_thread_file=${enable_threads}
     ;;
   *)
diff -ruN gcc-9.3.0/libgcc/config/sh/crt1.S gcc-9.3.0-kos/libgcc/config/sh/crt1.S
--- gcc-9.3.0/libgcc/config/sh/crt1.S	2020-03-12 07:07:23.000000000 -0400
+++ gcc-9.3.0-kos/libgcc/config/sh/crt1.S	2020-04-03 16:07:04.540000000 -0400
@@ -1,724 +1,197 @@
-/* Copyright (C) 2000-2019 Free Software Foundation, Inc.
-   This file was pretty much copied from newlib.
+! KallistiOS ##version##
+!
+! startup.s
+! (c)2000-2001 Dan Potter
+!
+! This file must appear FIRST in your linking order, or your program won't
+! work correctly as a raw binary.
+!
+! This is very loosely based on Marcus' crt0.s/startup.s
+!
+
+.globl start
+.globl _start
+.globl _arch_real_exit
+.globl __arch_old_sr
+.globl __arch_old_vbr
+.globl __arch_old_stack
+.globl __arch_old_fpscr
 
-This file is part of GCC.
-
-GCC is free software; you can redistribute it and/or modify it
-under the terms of the GNU General Public License as published by the
-Free Software Foundation; either version 3, or (at your option) any
-later version.
-
-GCC is distributed in the hope that it will be useful,
-but WITHOUT ANY WARRANTY; without even the implied warranty of
-MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-General Public License for more details.
-
-Under Section 7 of GPL version 3, you are granted additional
-permissions described in the GCC Runtime Library Exception, version
-3.1, as published by the Free Software Foundation.
-
-You should have received a copy of the GNU General Public License and
-a copy of the GCC Runtime Library Exception along with this program;
-see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
-<http://www.gnu.org/licenses/>.  */
-
-#include "crt.h"
-
-#ifdef MMU_SUPPORT
-	/* Section used for exception/timer interrupt stack area */
-	.section .data.vbr.stack,"aw"
-	.align 4
-	.global __ST_VBR
-__ST_VBR:
-	.zero 1024 * 2          /* ; 2k for VBR handlers */
-/* Label at the highest stack address where the stack grows from */
-__timer_stack:
-#endif /* MMU_SUPPORT */
-	
-	/* ;----------------------------------------
-	Normal newlib crt1.S */
-
-	! make a place to keep any previous value of the vbr register
-	! this will only have a value if it has been set by redboot (for example)
-	.section .bss
-old_vbr:
-	.long 0
-#ifdef PROFILE
-profiling_enabled:
-	.long 0
-#endif
-
-
-	.section .text
-	.global	start
-	.import ___rtos_profiler_start_timer
-	.weak   ___rtos_profiler_start_timer
+_start:
 start:
-	mov.l	stack_k,r15
-
-#if defined (__SH3__) || (defined (__SH_FPU_ANY__) && ! defined (__SH2E__) && ! defined (__SH2A__)) || defined (__SH4_NOFPU__)
-#define VBR_SETUP
-	! before zeroing the bss ...
-	! if the vbr is already set to vbr_start then the program has been restarted
-	! (i.e. it is not the first time the program has been run since reset)
-	! reset the vbr to its old value before old_vbr (in bss) is wiped
-	! this ensures that the later code does not create a circular vbr chain
-	stc	vbr, r1
-	mov.l	vbr_start_k, r2
-	cmp/eq	r1, r2
-	bf	0f
-	! reset the old vbr value
-	mov.l	old_vbr_k, r1
-	mov.l	@r1, r2
-	ldc	r2, vbr
-0:	
-#endif /* VBR_SETUP */
-	
-	! zero out bss
-	mov.l	edata_k,r0
-	mov.l	end_k,r1
-	mov	#0,r2
-start_l:
-	mov.l	r2,@r0
-	add	#4,r0
-	cmp/ge	r0,r1
-	bt	start_l
-
-#if defined (__SH_FPU_ANY__)
-	mov.l set_fpscr_k, r1
-	mov #4,r4
-	jsr @r1
-	shll16 r4	! Set DN bit (flush denormal inputs to zero)
-	lds r3,fpscr	! Switch to default precision
-#endif /* defined (__SH_FPU_ANY__) */
-
-#ifdef VBR_SETUP
-	! save the existing contents of the vbr
-	! there will only be a prior value when using something like redboot
-	! otherwise it will be zero
-	stc	vbr, r1
-	mov.l	old_vbr_k, r2
-	mov.l	r1, @r2
-	! setup vbr
-	mov.l	vbr_start_k, r1
-	ldc	r1,vbr
-#endif /* VBR_SETUP */
-
-	! if an rtos is exporting a timer start fn,
-	! then pick up an SR which does not enable ints
-	! (the rtos will take care of this)
-	mov.l rtos_start_fn, r0
-	mov.l sr_initial_bare, r1
-	tst	r0, r0
-	bt	set_sr
-
-	mov.l sr_initial_rtos, r1
-
-set_sr:
-	! Set status register (sr)
-	ldc	r1, sr
-
-	! arrange for exit to call fini
-	mov.l	atexit_k,r0
-	mov.l	fini_k,r4
-	jsr	@r0
+	! Disable interrupts (if they're enabled)
+	mov.l	old_sr_addr,r0
+	stc	sr,r1
+	mov.l	r1,@r0
+	mov.l	init_sr,r0
+	ldc	r0,sr
+
+	! Run in the P2 area
+	mov.l	setup_cache_addr,r0
+	mov.l	p2_mask,r1
+	or	r1,r0
+	jmp	@r0
 	nop
 
-#ifdef PROFILE
-	! arrange for exit to call _mcleanup (via stop_profiling)
-	mova    stop_profiling,r0
-	mov.l   atexit_k,r1
-	jsr     @r1
-	mov	r0, r4
-
-	! Call profiler startup code
-	mov.l monstartup_k, r0
-	mov.l start_k, r4
-	mov.l etext_k, r5
-	jsr @r0
+setup_cache:
+	! Now that we are in P2, it's safe to enable the cache
+	! Check to see if we should enable OCRAM.
+	mov.l	kos_init_flags_addr, r0
+	add	#2, r0
+	mov.w	@r0, r0
+	tst	#1, r0
+	bf	.L_setup_cache_L0
+	mov.w	ccr_data,r1
+	bra	.L_setup_cache_L1
+	nop
+.L_setup_cache_L0:
+	mov.w	ccr_data_ocram,r1
+.L_setup_cache_L1:
+	mov.l	ccr_addr,r0
+	mov.l	r1,@r0
+
+	! After changing CCR, eight instructions must be executed before
+	! it's safe to enter a cached area such as P1
+	nop			! 1
+	nop			! 2
+	nop			! 3
+	nop			! 4
+	nop			! 5 (d-cache now safe)
+	nop			! 6
+	mov.l	init_addr,r0	! 7
+	mov	#0,r1		! 8
+	jmp	@r0		! go
+	mov	r1,r0
 	nop
 
-	! enable profiling trap
-	! until now any trap 33s will have been ignored
-	! This means that all library functions called before this point
-	! (directly or indirectly) may have the profiling trap at the start.
-	! Therefore, only mcount itself may not have the extra header.
-	mov.l	profiling_enabled_k2, r0
-	mov	#1, r1
-	mov.l	r1, @r0
-#endif /* PROFILE */
+init:
+	! Save old PR on old stack so we can get to it later
+	sts.l	pr,@-r15
 
-	! call init
-	mov.l	init_k,r0
+	! Save the current stack, and set a new stack (higher up in RAM)
+	mov.l	old_stack_addr,r0
+	mov.l	r15,@r0
+	mov.l	new_stack,r15
+
+	! Save VBR
+	mov.l	old_vbr_addr,r0
+	stc	vbr,r1
+	mov.l	r1,@r0
+
+	! Save FPSCR
+	mov.l	old_fpscr_addr,r0
+	sts	fpscr,r1
+	mov.l	r1,@r0
+
+	! Reset FPSCR
+	mov	#4,r4		! Use 00040000 (DN=1)
+	mov.l	fpscr_addr,r0
 	jsr	@r0
-	nop
+	shll16	r4
 
-	! call the mainline	
-	mov.l	main_k,r0
-	jsr	@r0
-	nop
+	! Setup a sentinel value for frame pointer in case we're using
+	! FRAME_POINTERS for stack tracing.
+	mov	#-1,r14
 
-	! call exit
-	mov	r0,r4
-	mov.l	exit_k,r0
+	! Jump to the kernel main
+	mov.l	main_addr,r0
 	jsr	@r0
 	nop
-	
-		.balign 4
-#ifdef PROFILE
-stop_profiling:
-	# stop mcount counting
-	mov.l	profiling_enabled_k2, r0
-	mov	#0, r1
-	mov.l	r1, @r0
 
-	# call mcleanup
-	mov.l	mcleanup_k, r0
-	jmp	@r0
-	nop
-		
-		.balign 4
-mcleanup_k:
-	.long __mcleanup
-monstartup_k:
-	.long ___monstartup
-profiling_enabled_k2:
-	.long profiling_enabled
-start_k:
-	.long _start
-etext_k:
-	.long __etext
-#endif /* PROFILE */
-
-	.align 2
-#if defined (__SH_FPU_ANY__)
-set_fpscr_k:
-	.long	___set_fpscr
-#endif /*  defined (__SH_FPU_ANY__) */
-
-stack_k:
-	.long	_stack	
-edata_k:
-	.long	_edata
-end_k:
-	.long	_end
-main_k:
-	.long	___setup_argv_and_call_main
-exit_k:
-	.long	_exit
-atexit_k:
-	.long	_atexit
-init_k:
-	.long	GLOBAL(_init)
-fini_k:
-	.long	GLOBAL(_fini)
-#ifdef VBR_SETUP
-old_vbr_k:
-	.long	old_vbr
-vbr_start_k:
-	.long	vbr_start
-#endif /* VBR_SETUP */
-	
-sr_initial_rtos:
-	! Privileged mode RB 1 BL 0. Keep BL 0 to allow default trap handlers to work.
-	! Whether profiling or not, keep interrupts masked,
-	! the RTOS will enable these if required.
-	.long 0x600000f1 
-
-rtos_start_fn:
-	.long ___rtos_profiler_start_timer
-	
-#ifdef PROFILE
-sr_initial_bare:
-	! Privileged mode RB 1 BL 0. Keep BL 0 to allow default trap handlers to work.
-	! For bare machine, we need to enable interrupts to get profiling working
-	.long 0x60000001
-#else
-
-sr_initial_bare:
-	! Privileged mode RB 1 BL 0. Keep BL 0 to allow default trap handlers to work.
-	! Keep interrupts disabled - the application will enable as required.
-	.long 0x600000f1
-#endif
-
-	! supplied for backward compatibility only, in case of linking
-	! code whose main() was compiled with an older version of GCC.
-	.global ___main
-___main:
-	rts
-	nop
-#ifdef VBR_SETUP
-! Exception handlers	
-	.section .text.vbr, "ax"
-vbr_start:
-
-	.org 0x100
-vbr_100:
-#ifdef PROFILE
-	! Note on register usage.
-	! we use r0..r3 as scratch in this code. If we are here due to a trapa for profiling
-	! then this is OK as we are just before executing any function code.
-	! The other r4..r7 we save explicityl on the stack
-	! Remaining registers are saved by normal ABI conventions and we assert we do not
-	! use floating point registers.
-	mov.l expevt_k1, r1
-	mov.l @r1, r1
-	mov.l event_mask, r0
-	and r0,r1
-	mov.l trapcode_k, r2
-	cmp/eq r1,r2
-	bt 1f
-	bra handler_100   ! if not a trapa, go to default handler
-	nop
-1:	
-	mov.l trapa_k, r0
-	mov.l @r0, r0
-	shlr2 r0      ! trapa code is shifted by 2.
-	cmp/eq #33, r0
-	bt 2f
-	bra handler_100
-	nop
-2:	
-	
-	! If here then it looks like we have trap #33
-	! Now we need to call mcount with the following convention
-	! Save and restore r4..r7
-	mov.l	r4,@-r15
-	mov.l	r5,@-r15
-	mov.l	r6,@-r15
-	mov.l	r7,@-r15
-	sts.l	pr,@-r15
+	! Program can return here (not likely) or jump here directly
+	! from anywhere in it to go straight back to the monitor
+_arch_real_exit:
+	! Reset SR
+	mov.l	old_sr,r0
+	ldc	r0,sr
+
+	! Disable MMU, invalidate TLB
+	mov	#4,r0
+	mov.l	mmu_addr,r1
+	mov.l	r0,@r1
+
+	! Wait (just in case)
+	nop				! 1
+	nop				! 2
+	nop				! 3
+	nop				! 4
+	nop				! 5
+	nop				! 6
+	nop				! 7
+	nop				! 8
+	
+	! Restore VBR
+	mov.l	old_vbr,r0
+	ldc	r0,vbr
 
-	! r4 is frompc.
-	! r5 is selfpc
-	! r0 is the branch back address.
-	! The code sequence emitted by gcc for the profiling trap is
-	! .align 2
-	! trapa #33
-	! .align 2
-	! .long lab Where lab is planted by the compiler. This is the address
-	! of a datum that needs to be incremented. 
-	sts pr,  r4     ! frompc
-	stc spc, r5	! selfpc
-	mov #2, r2
-	not r2, r2      ! pattern to align to 4
-	and r2, r5      ! r5 now has aligned address
-!	add #4, r5      ! r5 now has address of address
-	mov r5, r2      ! Remember it.
-!	mov.l @r5, r5   ! r5 has value of lable (lab in above example)
-	add #8, r2
-	ldc r2, spc     ! our return address avoiding address word
-
-	! only call mcount if profiling is enabled
-	mov.l profiling_enabled_k, r0
-	mov.l @r0, r0
-	cmp/eq #0, r0
-	bt 3f
-	! call mcount
-	mov.l mcount_k, r2
-	jsr @r2
-	nop
-3:
-	lds.l @r15+,pr
-	mov.l @r15+,r7
-	mov.l @r15+,r6
-	mov.l @r15+,r5
-	mov.l @r15+,r4
-	rte
-	nop
-	.balign 4
-event_mask:
-	.long 0xfff
-trapcode_k:	
-	.long 0x160
-expevt_k1:
-	.long 0xff000024 ! Address of expevt
-trapa_k:	
-	.long 0xff000020
-mcount_k:
-	.long __call_mcount
-profiling_enabled_k:
-	.long profiling_enabled
-#endif
-	! Non profiling case.
-handler_100:
-	mov.l 2f, r0     ! load the old vbr setting (if any)
-	mov.l @r0, r0
-	cmp/eq #0, r0
-	bf 1f
-	! no previous vbr - jump to own generic handler
-	bra handler
-	nop	
-1:	! there was a previous handler - chain them
-	add #0x7f, r0	 ! 0x7f
-	add #0x7f, r0	 ! 0xfe
-	add #0x2, r0     ! add 0x100 without corrupting another register
-	jmp @r0
-	nop
-	.balign 4
-2:	
-	.long old_vbr
-
-	.org 0x400
-vbr_400:	! Should be at vbr+0x400
-	mov.l 2f, r0     ! load the old vbr setting (if any)
-	mov.l @r0, r0
-	cmp/eq #0, r0
-	! no previous vbr - jump to own generic handler
-	bt handler
-	! there was a previous handler - chain them
-	rotcr r0
-	rotcr r0
-	add #0x7f, r0	 ! 0x1fc
-	add #0x7f, r0	 ! 0x3f8
-	add #0x02, r0	 ! 0x400
-	rotcl r0
-	rotcl r0	 ! Add 0x400 without corrupting another register
-	jmp @r0
-	nop
-	.balign 4
-2:
-	.long old_vbr
-handler:
-	/* If the trap handler is there call it */
-	mov.l	superh_trap_handler_k, r0
-	cmp/eq	#0, r0       ! True if zero.
-	bf 3f
-	bra   chandler
-	nop
-3:	
-	! Here handler available, call it. 
-	/* Now call the trap handler with as much of the context unchanged as possible.
-	   Move trapping address into PR to make it look like the trap point */
-	stc spc, r1
-	lds r1, pr
-	mov.l expevt_k, r4
-	mov.l @r4, r4 ! r4 is value of expevt, first parameter.
-	mov r1, r5   ! Remember trapping pc.
-	mov r1, r6   ! Remember trapping pc.
-	mov.l chandler_k, r1
-	mov.l superh_trap_handler_k, r2
-	! jmp to trap handler to avoid disturbing pr. 
-	jmp @r2
-	nop
+	! If we're working under dcload, call its EXIT syscall
+	mov.l	dcload_magic_addr,r0
+	mov.l	@r0,r0
+	mov.l	dcload_magic_value,r1
+	cmp/eq	r0,r1
+	bf	normal_exit
 
-	.org 0x600
-vbr_600:
-#ifdef PROFILE	
-	! Should be at vbr+0x600
-	! Now we are in the land of interrupts so need to save more state. 
-	! Save register state
-	mov.l interrupt_stack_k, r15 ! r15 has been saved to sgr.
-	mov.l	r0,@-r15	
-	mov.l	r1,@-r15
-	mov.l	r2,@-r15
-	mov.l	r3,@-r15
-	mov.l	r4,@-r15
-	mov.l	r5,@-r15
-	mov.l	r6,@-r15
-	mov.l	r7,@-r15
-	sts.l	pr,@-r15
-	sts.l	mach,@-r15
-	sts.l	macl,@-r15
-#if defined(__SH_FPU_ANY__)
-	! Save fpul and fpscr, save fr0-fr7 in 64 bit mode
-	! and set the pervading precision for the timer_handler
-	mov	#0,r0
-	sts.l	fpul,@-r15
-	sts.l	fpscr,@-r15
-	lds	r0,fpscr	! Clear fpscr
-	fmov	fr0,@-r15
-	fmov	fr1,@-r15
-	fmov	fr2,@-r15
-	fmov	fr3,@-r15
-	mov.l	pervading_precision_k,r0
-	fmov	fr4,@-r15
-	fmov	fr5,@-r15
+	mov.l	dcload_syscall,r0
 	mov.l	@r0,r0
-	fmov	fr6,@-r15
-	fmov	fr7,@-r15
-	lds	r0,fpscr
-#endif /* __SH_FPU_ANY__ */
-	! Pass interrupted pc to timer_handler as first parameter (r4).
-	stc    spc, r4
-	mov.l timer_handler_k, r0
-	jsr @r0
-	nop
-#if defined(__SH_FPU_ANY__)
-	mov	#0,r0
-	lds	r0,fpscr	! Clear the fpscr
-	fmov	@r15+,fr7
-	fmov	@r15+,fr6
-	fmov	@r15+,fr5
-	fmov	@r15+,fr4
-	fmov	@r15+,fr3
-	fmov	@r15+,fr2
-	fmov	@r15+,fr1
-	fmov	@r15+,fr0
-	lds.l	@r15+,fpscr
-	lds.l	@r15+,fpul
-#endif /* __SH_FPU_ANY__ */
-	lds.l @r15+,macl
-	lds.l @r15+,mach
-	lds.l @r15+,pr
-	mov.l @r15+,r7
-	mov.l @r15+,r6
-	mov.l @r15+,r5
-	mov.l @r15+,r4
-	mov.l @r15+,r3
-	mov.l @r15+,r2
-	mov.l @r15+,r1
-	mov.l @r15+,r0
-	stc sgr, r15    ! Restore r15, destroyed by this sequence. 
-	rte
-	nop
-#if defined(__SH_FPU_ANY__)
-	.balign 4
-pervading_precision_k:
-	.long GLOBAL(__fpscr_values)+4
-#endif
-#else
-	mov.l 2f, r0     ! Load the old vbr setting (if any).
-	mov.l @r0, r0
-	cmp/eq #0, r0
-	! no previous vbr - jump to own handler
-	bt chandler
-	! there was a previous handler - chain them
-	rotcr r0
-	rotcr r0
-	add #0x7f, r0	 ! 0x1fc
-	add #0x7f, r0	 ! 0x3f8
-	add #0x7f, r0	 ! 0x5f4
-	add #0x03, r0	 ! 0x600
-	rotcl r0
-	rotcl r0	 ! Add 0x600 without corrupting another register
-	jmp @r0
-	nop
-	.balign 4
-2:
-	.long old_vbr
-#endif	 /* PROFILE code */
-chandler:
-	mov.l expevt_k, r4
-	mov.l @r4, r4 ! r4 is value of expevt hence making this the return code
-	mov.l handler_exit_k,r0
-	jsr   @r0
-	nop
-	! We should never return from _exit but in case we do we would enter the
-	! the following tight loop
-limbo:
-	bra limbo
-	nop
-	.balign 4
-#ifdef PROFILE
-interrupt_stack_k:
-	.long __timer_stack	! The high end of the stack
-timer_handler_k:
-	.long __profil_counter
-#endif
-expevt_k:
-	.long 0xff000024 ! Address of expevt
-chandler_k:	
-	.long chandler	
-superh_trap_handler_k:
-	.long	__superh_trap_handler
-handler_exit_k:
-	.long _exit
-	.align 2
-! Simulated compile of trap handler.
-	.section	.debug_abbrev,"",@progbits
-.Ldebug_abbrev0:
-	.section	.debug_info,"",@progbits
-.Ldebug_info0:
-	.section	.debug_line,"",@progbits
-.Ldebug_line0:
-	.text
-.Ltext0:
-	.align 5
-	.type	__superh_trap_handler,@function
-__superh_trap_handler:
-.LFB1:
-	mov.l	r14,@-r15
-.LCFI0:
-	add	#-4,r15
-.LCFI1:
-	mov	r15,r14
-.LCFI2:
-	mov.l	r4,@r14
-	lds	r1, pr
-	add	#4,r14
-	mov	r14,r15
-	mov.l	@r15+,r14
-	rts	
+	jsr	@r0
+	mov	#15,r4
+
+	! Set back the stack and return (presumably to a serial debug)
+normal_exit:
+	mov.l	old_stack,r15
+	lds.l	@r15+,pr
+	rts
 	nop
-.LFE1:
-.Lfe1:
-	.size	__superh_trap_handler,.Lfe1-__superh_trap_handler
-	.section	.debug_frame,"",@progbits
-.Lframe0:
-	.ualong	.LECIE0-.LSCIE0
-.LSCIE0:
-	.ualong	0xffffffff
-	.byte	0x1
-	.string	""
-	.uleb128 0x1
-	.sleb128 -4
-	.byte	0x11
-	.byte	0xc
-	.uleb128 0xf
-	.uleb128 0x0
-	.align 2
-.LECIE0:
-.LSFDE0:
-	.ualong	.LEFDE0-.LASFDE0
-.LASFDE0:
-	.ualong	.Lframe0
-	.ualong	.LFB1
-	.ualong	.LFE1-.LFB1
-	.byte	0x4
-	.ualong	.LCFI0-.LFB1
-	.byte	0xe
-	.uleb128 0x4
-	.byte	0x4
-	.ualong	.LCFI1-.LCFI0
-	.byte	0xe
-	.uleb128 0x8
-	.byte	0x8e
-	.uleb128 0x1
-	.byte	0x4
-	.ualong	.LCFI2-.LCFI1
-	.byte	0xd
-	.uleb128 0xe
-	.align 2
-.LEFDE0:
-	.text
-.Letext0:
-	.section	.debug_info
-	.ualong	0xb3
-	.uaword	0x2
-	.ualong	.Ldebug_abbrev0
-	.byte	0x4
-	.uleb128 0x1
-	.ualong	.Ldebug_line0
-	.ualong	.Letext0
-	.ualong	.Ltext0
-	.string	"trap_handler.c"
-	.string	"xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
-	.string	"GNU C 3.2 20020529 (experimental)"
-	.byte	0x1
-	.uleb128 0x2
-	.ualong	0xa6
-	.byte	0x1
-	.string	"_superh_trap_handler"
-	.byte	0x1
-	.byte	0x2
-	.byte	0x1
-	.ualong	.LFB1
-	.ualong	.LFE1
-	.byte	0x1
-	.byte	0x5e
-	.uleb128 0x3
-	.string	"trap_reason"
-	.byte	0x1
-	.byte	0x1
-	.ualong	0xa6
-	.byte	0x2
-	.byte	0x91
-	.sleb128 0
-	.byte	0x0
-	.uleb128 0x4
-	.string	"unsigned int"
-	.byte	0x4
-	.byte	0x7
-	.byte	0x0
-	.section	.debug_abbrev
-	.uleb128 0x1
-	.uleb128 0x11
-	.byte	0x1
-	.uleb128 0x10
-	.uleb128 0x6
-	.uleb128 0x12
-	.uleb128 0x1
-	.uleb128 0x11
-	.uleb128 0x1
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x1b
-	.uleb128 0x8
-	.uleb128 0x25
-	.uleb128 0x8
-	.uleb128 0x13
-	.uleb128 0xb
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x2
-	.uleb128 0x2e
-	.byte	0x1
-	.uleb128 0x1
-	.uleb128 0x13
-	.uleb128 0x3f
-	.uleb128 0xc
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x3a
-	.uleb128 0xb
-	.uleb128 0x3b
-	.uleb128 0xb
-	.uleb128 0x27
-	.uleb128 0xc
-	.uleb128 0x11
-	.uleb128 0x1
-	.uleb128 0x12
-	.uleb128 0x1
-	.uleb128 0x40
-	.uleb128 0xa
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x5
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x3a
-	.uleb128 0xb
-	.uleb128 0x3b
-	.uleb128 0xb
-	.uleb128 0x49
-	.uleb128 0x13
-	.uleb128 0x2
-	.uleb128 0xa
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x4
-	.uleb128 0x24
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0xb
-	.uleb128 0xb
-	.uleb128 0x3e
-	.uleb128 0xb
-	.byte	0x0
-	.byte	0x0
-	.byte	0x0
-	.section	.debug_pubnames,"",@progbits
-	.ualong	0x27
-	.uaword	0x2
-	.ualong	.Ldebug_info0
-	.ualong	0xb7
-	.ualong	0x67
-	.string	"_superh_trap_handler"
-	.ualong	0x0
-	.section	.debug_aranges,"",@progbits
-	.ualong	0x1c
-	.uaword	0x2
-	.ualong	.Ldebug_info0
-	.byte	0x4
-	.byte	0x0
-	.uaword	0x0
-	.uaword	0x0
-	.ualong	.Ltext0
-	.ualong	.Letext0-.Ltext0
-	.ualong	0x0
-	.ualong	0x0
-#endif /* VBR_SETUP */
+
+! Misc variables
+	.align	2
+dcload_magic_addr:
+	.long	0x8c004004
+dcload_magic_value:
+	.long	0xdeadbeef
+dcload_syscall:
+	.long	0x8c004008
+__arch_old_sr:
+old_sr:
+	.long	0
+__arch_old_vbr:
+old_vbr:
+	.long	0
+__arch_old_fpscr:
+old_fpscr:
+	.long	0
+init_sr:
+	.long	0x500000f0
+old_sr_addr:
+	.long	old_sr
+old_vbr_addr:
+	.long	old_vbr
+old_fpscr_addr:
+	.long	old_fpscr
+old_stack_addr:
+	.long	old_stack
+__arch_old_stack:
+old_stack:
+	.long	0
+new_stack:
+	.long	0x8d000000
+p2_mask:
+	.long	0xa0000000
+setup_cache_addr:
+	.long	setup_cache
+init_addr:
+	.long	init
+main_addr:
+	.long	_arch_main
+mmu_addr:
+	.long	0xff000010
+fpscr_addr:
+	.long	___set_fpscr	! in libgcc
+kos_init_flags_addr:
+	.long	___kos_init_flags
+ccr_addr:
+	.long	0xff00001c
+ccr_data:
+	.word	0x090d
+ccr_data_ocram:
+	.word	0x092d
diff -ruN gcc-9.3.0/libgcc/config/sh/fake-kos.S gcc-9.3.0-kos/libgcc/config/sh/fake-kos.S
--- gcc-9.3.0/libgcc/config/sh/fake-kos.S	1969-12-31 19:00:00.000000000 -0500
+++ gcc-9.3.0-kos/libgcc/config/sh/fake-kos.S	2020-04-03 16:07:04.540000000 -0400
@@ -0,0 +1,78 @@
+! Weakly linked symbols used to get GCC to hopefully compile itself properly.
+! These will be replaced by the real symbols in actual compiled programs.
+
+    ! crt1.S required symbols
+    .weak   ___kos_init_flags
+    .weak   _arch_main
+
+    ! Things needed by emutls
+    .weak   _free
+    .weak   _abort
+    .weak   _malloc
+    .weak   _realloc
+    .weak   _calloc
+
+    ! gthr-kos.h required symbols
+    .weak   _mutex_is_locked
+    .weak   _mutex_destroy
+    .weak   _mutex_lock
+    .weak   _mutex_unlock
+    .weak   _mutex_trylock
+    .weak   _mutex_lock_timed
+    .weak   _mutex_init
+
+    .weak   _thd_create
+    .weak   _thd_join
+    .weak   _thd_detach
+    .weak   _thd_pass
+    .weak   _thd_exit
+    .weak   _thd_get_current
+
+    .weak   _kthread_setspecific
+    .weak   _kthread_getspecific
+    .weak   _kthread_key_create
+    .weak   _kthread_key_delete
+    .weak   _kthread_once
+
+    .weak   _cond_destroy
+    .weak   _cond_init
+    .weak   _cond_wait
+    .weak   _cond_wait_timed
+    .weak   _cond_broadcast
+    .weak   _cond_signal
+
+___kos_init_flags:
+    .long   0
+
+_arch_main:
+_free:
+_abort:
+_malloc:
+_realloc:
+_calloc:
+_mutex_is_locked:
+_mutex_destroy:
+_mutex_lock:
+_mutex_unlock:
+_mutex_trylock:
+_mutex_lock_timed:
+_mutex_init:
+_thd_create:
+_thd_join:
+_thd_detach:
+_thd_pass:
+_thd_exit:
+_thd_get_current:
+_kthread_setspecific:
+_kthread_getspecific:
+_kthread_key_create:
+_kthread_key_delete:
+_kthread_once:
+_cond_destroy:
+_cond_init:
+_cond_wait:
+_cond_wait_timed:
+_cond_broadcast:
+_cond_signal:
+    rts
+    mov     #-1, r0
diff -ruN gcc-9.3.0/libgcc/config/sh/gthr-kos.h gcc-9.3.0-kos/libgcc/config/sh/gthr-kos.h
--- gcc-9.3.0/libgcc/config/sh/gthr-kos.h	1969-12-31 19:00:00.000000000 -0500
+++ gcc-9.3.0-kos/libgcc/config/sh/gthr-kos.h	2020-04-03 16:07:04.540000000 -0400
@@ -0,0 +1,401 @@
+/* Copyright (C) 2009, 2010, 2011, 2012, 2020 Lawrence Sebald */
+
+/* Threads compatibility routines for libgcc2 and libobjc.  */
+/* Compile this one with gcc.  */
+/* Copyright (C) 1997-2019 Free Software Foundation, Inc.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 3, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+#ifndef GCC_GTHR_KOS_H
+#define GCC_GTHR_KOS_H
+
+/* KallistiOS threads specific definitions. */
+
+#define __GTHREADS 1
+#define __GTHREADS_CXX0X 1
+#define __GTHREAD_HAS_COND 1
+
+#include <kos/thread.h>
+#include <kos/tls.h>
+#include <kos/mutex.h>
+#include <kos/once.h>
+#include <kos/cond.h>
+#include <arch/irq.h>
+#include <time.h>
+
+/* These should work just fine. */
+typedef kthread_key_t __gthread_key_t;
+typedef kthread_once_t __gthread_once_t;
+typedef mutex_t __gthread_mutex_t;
+typedef mutex_t __gthread_recursive_mutex_t;
+typedef condvar_t __gthread_cond_t;
+typedef kthread_t *__gthread_t;
+typedef struct timespec __gthread_time_t;
+
+#define __GTHREAD_ONCE_INIT KTHREAD_ONCE_INIT
+#define __GTHREAD_MUTEX_INIT MUTEX_INITIALIZER
+#define __GTHREAD_RECURSIVE_MUTEX_INIT RECURSIVE_MUTEX_INITIALIZER
+#define __GTHREAD_COND_INIT COND_INITIALIZER
+#define __GTHREAD_TIME_INIT {0,0}
+
+#define __GTHREAD_MUTEX_INIT_FUNCTION __gthread_mutex_init_func
+
+#ifdef _GTHREAD_USE_MUTEX_INIT_FUNC
+# undef __GTHREAD_MUTEX_INIT
+#endif
+#ifdef _GTHREAD_USE_RECURSIVE_MUTEX_INIT_FUNC
+# undef __GTHREAD_RECURSIVE_MUTEX_INIT
+# undef __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION
+# define __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION __gthread_recursive_mutex_init_func
+#endif
+#ifdef _GTHREAD_USE_COND_INIT_FUNC
+# undef __GTHREAD_COND_INIT
+# define __GTHREAD_COND_INIT_FUNCTION __gthread_cond_init_func
+#endif
+
+
+static inline int __gthread_active_p(void) {
+    return 1;
+}
+
+#ifdef _LIBOBJC
+
+/* This stuff only applies to Objective C. */
+
+/* The config.h file in libobjc/ */
+#include <config.h>
+
+/* Key structure for maintaining thread specific storage */
+static kthread_key_t _objc_thread_storage;
+
+/* Backend initialization funcitons */
+
+/* Initialize the threads subsystem. */
+static inline int __gthread_objc_init_thread_system(void) {
+    /* The only thing we have to do is to initialize the storage key. */
+    return kthread_key_create(&_objc_thread_storage, NULL);
+}
+
+/* Close the threads subsystem. */
+static inline int __gthread_objc_close_thread_system(void) {
+    return kthread_key_delete(_objc_thread_storage);
+}
+
+/* Backend thread functions */
+
+/* Create a new thread of execution. */
+static inline objc_thread_t __gthread_objc_thread_detach(void (*func)(void *),
+                                                         void *arg) {
+    kthread_t *thd_hnd;
+
+    /* Objective C threads are detached by default. */
+    thd_hnd = thd_create(1, (void *)(void *)func, arg);
+    return (objc_thread_t)thd_hnd;
+}
+
+/* Set the current thread's priority. */
+static inline int __gthread_objc_thread_set_priority(int priority __attribute__((unused))) {
+    /* XXXX */
+    return -1;
+}
+
+/* Return the current thread's priority. */
+static inline int __gthread_objc_thread_get_priority(void) {
+    /* XXXX */
+    return OBJC_THREAD_INTERACTIVE_PRIORITY;
+}
+
+/* Yield our process time to another thread. */
+static inline void __gthread_objc_thread_yield(void) {
+    thd_pass();
+}
+
+/* Terminate the current thread. */
+static inline int __gthread_objc_thread_exit(void) {
+    thd_exit(NULL);
+
+    /* We shouldn't get here... */
+    return -1;
+}
+
+/* Returns an integer value which uniquely describes a thread. */
+static inline objc_thread_t __gthread_objc_thread_id(void) {
+    return (objc_thread_t)thd_get_current();
+}
+
+/* Sets the thread's local storage pointer. */
+static inline int __gthread_objc_thread_set_data(void *value) {
+    return kthread_setspecific(_objc_thread_storage, value);
+}
+
+/* Returns the thread's local storage pointer. */
+static inline void *__gthread_objc_thread_get_data(void) {
+    return kthread_getspecific(_objc_thread_storage);
+}
+
+/* Backend mutex functions */
+
+/* Allocate a mutex. */
+static inline int __gthread_objc_mutex_allocate(objc_mutex_t mutex) {
+    mutex->backend = objc_malloc(sizeof(mutex_t));
+
+    if(mutex_init((mutex_t *)mutex->backend, MUTEX_TYPE_NORMAL)) {
+        objc_free(mutex->backend);
+        mutex->backend = NULL;
+        return -1;
+    }
+
+    return 0;
+}
+
+/* Deallocate a mutex. */
+static inline int __gthread_objc_mutex_deallocate(objc_mutex_t mutex) {
+    mutex_t *m = (mutex_t *)mutex->backend;
+    uint32 old;
+
+    old = irq_disable();
+
+    while(mutex_is_locked(m)) {
+        mutex_unlock(m);
+    }
+
+    if(mutex_destroy(m))
+        return -1;
+
+    mutex->backend = NULL;
+    irq_restore(old);
+
+    objc_free(m);
+
+    return 0;
+}
+
+/* Grab a lock on a mutex. */
+static inline int __gthread_objc_mutex_lock(objc_mutex_t mutex) {
+    return mutex_lock((mutex_t *)mutex->backend);
+}
+
+/* Try to grab a lock on a mutex. */
+static inline int __gthread_objc_mutex_trylock(objc_mutex_t mutex) {
+    return mutex_trylock((mutex_t *)mutex->backend);
+}
+
+/* Unlock the mutex. */
+static inline int __gthread_objc_mutex_unlock(objc_mutex_t mutex) {
+    return mutex_unlock((mutex_t *)mutex->backend);
+}
+
+/* Backend condition mutex functions */
+
+/* Allocate a condition. */
+static inline int __gthread_objc_condition_allocate(objc_condition_t cond) {
+    cond->backend = objc_malloc(sizeof(condvar_t));
+
+    if(cond_init((condvar_t *)cond->backend)) {
+        objc_free(cond->backend);
+        cond->backend = NULL;
+        return -1;
+    }
+
+    return 0;
+}
+
+/* Deallocate a condition. */
+static inline int __gthread_objc_condition_deallocate(objc_condition_t cond) {
+    if(cond_destroy((condvar_t *)cond->backend))
+        return -1;
+
+    objc_free(cond->backend);
+    cond->backend = NULL;
+    return 0;
+}
+
+/* Wait on the condition. */
+static inline int __gthread_objc_condition_wait(objc_condition_t cond,
+                                                objc_mutex_t mutex) {
+    return cond_wait((condvar_t *)cond->backend, (mutex_t *)mutex->backend);
+}
+
+/* Wake up all threads waiting on this condition. */
+static inline int __gthread_objc_condition_broadcast(objc_condition_t cond) {
+    return cond_broadcast((condvar_t *)cond->backend);
+}
+
+/* Wake up one thread waiting on this condition. */
+static inline int __gthread_objc_condition_signal(objc_condition_t cond) {
+    return cond_signal((condvar_t *)cond->backend);
+}
+
+#else /* _LIBOBJC */
+
+static inline int __gthread_create(__gthread_t *thd, void *(*func)(void *),
+                                   void *args) {
+    /* Non Objective C threads are joinable by default. */
+    *thd = thd_create(0, func, args);
+    return (*thd == NULL);
+}
+
+static inline int __gthread_join(__gthread_t thd, void **value_ptr) {
+    return thd_join(thd, value_ptr);
+}
+
+static inline int __gthread_detach(__gthread_t thd) {
+    return thd_detach(thd);
+}
+
+static inline int __gthread_equal(__gthread_t t1, __gthread_t t2) {
+    return t1 == t2;
+}
+
+static inline __gthread_t __gthread_self(void) {
+    return thd_get_current();
+}
+
+static inline int __gthread_yield(void) {
+    thd_pass();
+    return 0;
+}
+
+static inline int __gthread_once(__gthread_once_t *__once,
+                                 void (*__func)(void)) {
+    return kthread_once(__once, __func);
+}
+
+static inline int __gthread_key_create(__gthread_key_t *__key,
+                                       void (*__func)(void *)) {
+    return kthread_key_create(__key, __func);
+}
+
+static int __gthread_key_delete(__gthread_key_t __key) {
+    return kthread_key_delete(__key);
+}
+
+static inline void *__gthread_getspecific(__gthread_key_t __key) {
+    return kthread_getspecific(__key);
+}
+
+static inline int __gthread_setspecific(__gthread_key_t __key,
+                                        const void *__v) {
+    return kthread_setspecific(__key, __v);
+}
+
+static inline void __gthread_mutex_init_func(__gthread_mutex_t *__mutex) {
+    (void)mutex_init(__mutex, MUTEX_TYPE_NORMAL);
+}
+
+static inline int __gthread_mutex_destroy(__gthread_mutex_t *__mutex) {
+    return mutex_destroy(__mutex);
+}
+
+static inline int __gthread_mutex_lock(__gthread_mutex_t *__mutex) {
+    return mutex_lock(__mutex);
+}
+
+static inline int __gthread_mutex_trylock(__gthread_mutex_t *__mutex) {
+    return mutex_trylock(__mutex);
+}
+
+#if _GTHREAD_USE_MUTEX_TIMEDLOCK
+static inline int __gthread_mutex_timedlock(__gthread_mutex_t *m,
+                                            const __gthread_time_t *timeout) {
+    int t = (int)(timeout->tv_sec + (timeout->tv_nsec / 1000));
+    return mutex_lock_timed(m, t);
+}
+#endif
+
+static inline int __gthread_mutex_unlock(__gthread_mutex_t *__mutex) {
+    return mutex_unlock(__mutex);
+}
+
+static inline void __gthread_recursive_mutex_init_func(__gthread_recursive_mutex_t *__mutex) {
+    (void)mutex_init(__mutex, MUTEX_TYPE_RECURSIVE);
+}
+
+static inline int __gthread_recursive_mutex_lock(__gthread_recursive_mutex_t *__mutex) {
+    return mutex_lock(__mutex);
+}
+
+static inline int __gthread_recursive_mutex_trylock(__gthread_recursive_mutex_t *__mutex) {
+    return mutex_trylock(__mutex);
+}
+
+#if _GTHREAD_USE_MUTEX_TIMEDLOCK
+static inline int __gthread_recursive_mutex_timedlock(__gthread_recursive_mutex_t *m,
+                                                      const __gthread_time_t *timeout) {
+    int t = (int)(timeout->tv_sec + (timeout->tv_nsec / 1000));
+    return mutex_lock_timed(m, t);
+}
+#endif
+
+static inline int __gthread_recursive_mutex_unlock(__gthread_recursive_mutex_t *__mutex) {
+    return mutex_unlock(__mutex);
+}
+
+static inline int __gthread_recursive_mutex_destroy(__gthread_recursive_mutex_t *__mutex) {
+    return mutex_destroy(__mutex);
+}
+
+#ifdef _GTHREAD_USE_COND_INIT_FUNC
+static inline void __gthread_cond_init_func(__gthread_cond_t *__cond) {
+    (void)cond_init(__cond);
+}
+#endif
+
+static inline int __gthread_cond_broadcast(__gthread_cond_t *cond) {
+    return cond_broadcast(cond);
+}
+
+static inline int __gthread_cond_signal(__gthread_cond_t *cond) {
+    return cond_signal(cond);
+}
+
+static inline int __gthread_cond_wait(__gthread_cond_t *cond, __gthread_mutex_t *mutex) {
+    return cond_wait(cond, mutex);
+}
+
+static inline int __gthread_cond_timedwait(__gthread_cond_t *cond,
+                                           __gthread_mutex_t *mutex,
+                                           const __gthread_time_t *timeout) {
+    int t = (int)(timeout->tv_sec + (timeout->tv_nsec / 1000));
+    return cond_wait_timed(cond, mutex, t);
+}
+
+static inline int __gthread_cond_wait_recursive(__gthread_cond_t *cond,
+                                                __gthread_recursive_mutex_t *mutex) {
+    return cond_wait(cond, mutex);
+}
+
+static inline int __gthread_cond_timedwait_recursive(__gthread_cond_t *cond,
+                                                     __gthread_recursive_mutex_t *l,
+                                                     const __gthread_time_t *timeout) {
+    int t = (int)(timeout->tv_sec + (timeout->tv_nsec / 1000));
+    return cond_wait_timed(cond, l, t);
+}
+
+static inline int __gthread_cond_destroy(__gthread_cond_t *cond) {
+    return cond_destroy(cond);
+}
+
+#endif /* !_LIBOBJC */
+
+
+#endif /* ! GCC_GTHR_KOS_H */
diff -ruN gcc-9.3.0/libgcc/config/sh/t-sh gcc-9.3.0-kos/libgcc/config/sh/t-sh
--- gcc-9.3.0/libgcc/config/sh/t-sh	2020-03-12 07:07:23.000000000 -0400
+++ gcc-9.3.0-kos/libgcc/config/sh/t-sh	2020-04-03 16:07:04.540000000 -0400
@@ -23,6 +23,8 @@
   $(LIB1ASMFUNCS_CACHE)
 LIB1ASMFUNCS_CACHE = _ic_invalidate _ic_invalidate_array
 
+LIB2ADD = $(srcdir)/config/sh/fake-kos.S
+
 crt1.o: $(srcdir)/config/sh/crt1.S
 	$(gcc_compile) -c $<
 
diff -ruN gcc-9.3.0/libgcc/configure gcc-9.3.0-kos/libgcc/configure
--- gcc-9.3.0/libgcc/configure	2020-03-12 07:07:23.000000000 -0400
+++ gcc-9.3.0-kos/libgcc/configure	2020-04-03 16:07:04.540000000 -0400
@@ -5550,6 +5550,7 @@
     tpf)	thread_header=config/s390/gthr-tpf.h ;;
     vxworks)	thread_header=config/gthr-vxworks.h ;;
     win32)	thread_header=config/i386/gthr-win32.h ;;
+    kos)    thread_header=config/sh/gthr-kos.h ;;
 esac
 
 
diff -ruN gcc-9.3.0/libstdc++-v3/config/cpu/sh/atomicity.h gcc-9.3.0-kos/libstdc++-v3/config/cpu/sh/atomicity.h
--- gcc-9.3.0/libstdc++-v3/config/cpu/sh/atomicity.h	2020-03-12 07:07:24.000000000 -0400
+++ gcc-9.3.0-kos/libstdc++-v3/config/cpu/sh/atomicity.h	2020-04-03 16:07:04.540000000 -0400
@@ -22,14 +22,40 @@
 // see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
 // <http://www.gnu.org/licenses/>.
 
-// Use the default atomicity stuff, which will use __atomic* builtins
-// if threads are available, or the *_single functions on single-thread
-// configurations.
-// Actually we wouldn't need this header at all, but because of PR 53579
-// libstdc++'s configury will not pickup the -matomic-model= option when
-// set in the environment.  This makes it impossible to enable the proper
-// atomic model on SH without modifying GCC itself, because libstdc++ always
-// thinks the target doesn't do any atomics and uses the default mutex based
-// implementation from cpu/generic/atomicity_mutex.
+/* This is generic/atomicity.h */
 
 #include <ext/atomicity.h>
+#include <ext/concurrence.h>
+
+namespace 
+{
+  __gnu_cxx::__mutex&
+  get_atomic_mutex()
+  {
+    static __gnu_cxx::__mutex atomic_mutex;
+    return atomic_mutex;
+  }
+} // anonymous namespace
+
+namespace __gnu_cxx _GLIBCXX_VISIBILITY(default)
+{
+_GLIBCXX_BEGIN_NAMESPACE_VERSION
+
+  _Atomic_word
+  __attribute__ ((__unused__))
+  __exchange_and_add(volatile _Atomic_word* __mem, int __val) throw ()
+  {
+    __gnu_cxx::__scoped_lock sentry(get_atomic_mutex());
+    _Atomic_word __result;
+    __result = *__mem;
+    *__mem += __val;
+    return __result;
+  }
+
+  void
+  __attribute__ ((__unused__))
+  __atomic_add(volatile _Atomic_word* __mem, int __val) throw ()
+  { __exchange_and_add(__mem, __val); }
+
+_GLIBCXX_END_NAMESPACE_VERSION
+} // namespace
diff -ruN gcc-9.3.0/libstdc++-v3/configure gcc-9.3.0-kos/libstdc++-v3/configure
--- gcc-9.3.0/libstdc++-v3/configure	2020-03-12 07:07:24.000000000 -0400
+++ gcc-9.3.0-kos/libstdc++-v3/configure	2020-04-03 16:07:04.540000000 -0400
@@ -15629,6 +15629,7 @@
     tpf)	thread_header=config/s390/gthr-tpf.h ;;
     vxworks)	thread_header=config/gthr-vxworks.h ;;
     win32)	thread_header=config/i386/gthr-win32.h ;;
+    kos)    thread_header=config/sh/gthr-kos.h ;;
 esac
 
 
